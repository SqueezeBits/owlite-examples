diff --git a/main.py b/main.py
new file mode 100644
index 00000000..32999041
--- /dev/null
+++ b/main.py
@@ -0,0 +1,172 @@
+import argparse
+import random
+import torch
+import torch.backends.cudnn as cudnn
+from ultralytics import YOLO
+import owlite
+
+
+def get_parser():
+    parser = argparse.ArgumentParser()
+    parser.add_argument(
+        "--model-dir",
+        type=str,
+        default="./yolov8s.pt",
+        help="model directory to use",
+    )
+    parser.add_argument(
+        "--data-cfg",
+        type=str,
+        default="ultralytics/cfg/datasets/coco.yaml",
+        help="dataset config file (default: coco.yaml)",
+    )
+    parser.add_argument(
+        "--task",
+        type=str,
+        default="detect",
+        choices=["detect", "pose"],
+        help="task of model (default: detect)",
+    )
+    parser.add_argument(
+        "--gpu",
+        type=str,
+        default="",
+        help="gpu number to use",
+    )
+    parser.add_argument(
+        "--batch-size",
+        type=int,
+        default=32,
+        help="batch size for evaluation",
+    )
+    parser.add_argument(
+        "--seed",
+        type=int,
+        default=42,
+        help="global training seed",
+    )
+
+    subparsers = parser.add_subparsers(required=True)
+    owlite_parser = subparsers.add_parser("owlite", help="Owlite arguments")
+    owlite_parser.add_argument(
+        "--project",
+        type=str,
+        required=True,
+        dest="owlite_project",
+        help="OwLite project name",
+    )
+    owlite_parser.add_argument(
+        "--baseline",
+        type=str,
+        required=True,
+        dest="owlite_baseline",
+        help="OwLite baseline name",
+    )
+    owlite_parser.add_argument(
+        "--experiment",
+        type=str,
+        default=None,
+        dest="owlite_experiment",
+        help="OwLite experiment name",
+    )
+    owlite_parser.add_argument(
+        "--duplicate-from",
+        type=str,
+        default=None,
+        dest="owlite_duplicate_from",
+        help="The name of Owlite experiment where the config to be duplicated is located",
+    )
+    owlite_parser.add_argument(
+        "--ptq",
+        action="store_true",
+        dest="owlite_ptq",
+        help="True if OwLite PTQ is applied",
+    )
+    owlite_parser.add_argument(
+        "--calib-num",
+        type=int,
+        default=256,
+        dest="owlite_calib_num",
+        help="Number of data to use for Owlite calibration",
+    )
+    
+    return parser.parse_args()
+
+
+def main():
+    args = get_parser()
+    if args.seed is not None:
+        torch.manual_seed(args.seed)
+        random.seed(args.seed)
+        cudnn.deterministic = True
+        cudnn.benchmark = False
+
+    yolo = YOLO(args.model_dir)
+    detect = yolo.model.model[-1]
+    img = torch.randn(args.batch_size, 3, 640, 640)
+    detect.shape = img.shape
+    detect.export = True
+    detect.format = "onnx"
+
+    if torch.cuda.is_available():
+        if args.gpu:
+            device = torch.device(f"cuda:{args.gpu}")
+        else:
+            device = torch.device("cuda")
+    else:
+        device = torch.device("cpu")
+
+    # Initialize OwLite with user settings
+    owl = owlite.init(
+        project=args.owlite_project,
+        baseline=args.owlite_baseline,
+        experiment=args.owlite_experiment,
+        duplicate_from=args.owlite_duplicate_from,
+    )
+
+    # OwLite Model Quantization
+    example_input = torch.randn(args.batch_size, 3, 640, 640).to(
+        device
+    )
+    yolo.model.to(device)
+    yolo.model(example_input)
+
+    owlite_model = owl.convert(yolo.model.eval(), example_input)
+
+    # Initialize OwLite YOLO Model
+    owlite_model.stride = yolo.model.stride.to(device)
+    owlite_model.names = yolo.model.names
+    owlite_model.to(device)
+    
+    # TrainLoader for Model Calibration
+    trainer = yolo._smart_load("trainer")(
+        overrides={"data": args.data_cfg, "batch": args.batch_size, "rect": False}
+    )
+    train_loader = trainer.get_dataloader(
+        dataset_path=trainer.trainset,
+        batch_size=trainer.batch_size,
+        rank=-1,
+        mode="train",
+    )
+    
+    # OwLite Model Calibration
+    if args.owlite_ptq:
+        with owlite.calibrate(owlite_model) as calibrate_model:
+            for i, batch in enumerate(train_loader):
+                if i > 0 and i >= args.owlite_calib_num // args.batch_size:
+                    break
+                batch = trainer.preprocess_batch(batch)
+                calibrate_model(batch["img"].to(device))
+    yolo.model = owlite_model
+
+    # Benchmark the model using OwLite
+    metrics = yolo.val(data=args.data_cfg, batch=args.batch_size, rect=False)
+    owl.export(owlite_model)
+    owl.benchmark()
+    map50_95_metrics_key = "metrics/mAP50-95(B)" if args.task == "detect" else "metrics/mAP50-95(P)"
+    owl.log(mAP=metrics.results_dict[map50_95_metrics_key])
+    return
+
+
+if __name__ == "__main__":
+    main()
diff --git a/ultralytics/data/build.py b/ultralytics/data/build.py
index df342503..60357bf8 100644
--- a/ultralytics/data/build.py
+++ b/ultralytics/data/build.py
@@ -142,6 +142,7 @@ def build_dataloader(dataset, batch, workers, shuffle=True, rank=-1):
         collate_fn=getattr(dataset, "collate_fn", None),
         worker_init_fn=seed_worker,
         generator=generator,
+        drop_last=True,
     )
 
 
diff --git a/ultralytics/engine/validator.py b/ultralytics/engine/validator.py
index 8a2765c9..c0d664ec 100644
--- a/ultralytics/engine/validator.py
+++ b/ultralytics/engine/validator.py
@@ -154,7 +154,7 @@ class BaseValidator:
             self.dataloader = self.dataloader or self.get_dataloader(self.data.get(self.args.split), self.args.batch)
 
             model.eval()
-            model.warmup(imgsz=(1 if pt else self.args.batch, 3, imgsz, imgsz))  # warmup
+            model.warmup(imgsz=(self.args.batch, 3, imgsz, imgsz))  # warmup
 
         self.run_callbacks("on_val_start")
         dt = (
diff --git a/ultralytics/nn/autobackend.py b/ultralytics/nn/autobackend.py
index cde35a57..4c85be57 100644
--- a/ultralytics/nn/autobackend.py
+++ b/ultralytics/nn/autobackend.py
@@ -87,7 +87,7 @@ class AutoBackend(nn.Module):
         data=None,
         fp16=False,
         batch=1,
-        fuse=True,
+        fuse=False,
         verbose=True,
     ):
         """
@@ -453,8 +453,14 @@ class AutoBackend(nn.Module):
 
         # PyTorch
         if self.pt or self.nn_module:
-            y = self.model(im, augment=augment, visualize=visualize, embed=embed)
-
+            kwargs = {}
+            if augment is not None:
+                kwargs['augment'] = augment
+            if visualize is not None:
+                kwargs['visualize'] = visualize
+            if embed is not None:
+                kwargs['augment'] = embed
+            y = self.model(im, **kwargs) if not kwargs else self.model(im)
         # TorchScript
         elif self.jit:
             y = self.model(im)
diff --git a/ultralytics/nn/modules/block.py b/ultralytics/nn/modules/block.py
index 672f0964..a4707669 100644
--- a/ultralytics/nn/modules/block.py
+++ b/ultralytics/nn/modules/block.py
@@ -141,7 +141,8 @@ class HGBlock(nn.Module):
     def forward(self, x):
         """Forward pass of a PPHGNetV2 backbone layer."""
         y = [x]
-        y.extend(m(y[-1]) for m in self.m)
+        for m in self.m:
+            y.append(m(y[-1]))
         y = self.ec(self.sc(torch.cat(y, 1)))
         return y + x if self.add else y
 
@@ -180,10 +181,10 @@ class SPPF(nn.Module):
 
     def forward(self, x):
         """Forward pass through Ghost Convolution block."""
-        y = [self.cv1(x)]
-        y.extend(self.m(y[-1]) for _ in range(3))
-        return self.cv2(torch.cat(y, 1))
-
+        x = self.cv1(x)
+        y1 = self.m(x)
+        y2 = self.m(y1)
+        return self.cv2(torch.cat((x, y1, y2, self.m(y2)), 1))
 
 class C1(nn.Module):
     """CSP Bottleneck with 1 convolution."""
@@ -236,13 +237,15 @@ class C2f(nn.Module):
     def forward(self, x):
         """Forward pass through C2f layer."""
         y = list(self.cv1(x).chunk(2, 1))
-        y.extend(m(y[-1]) for m in self.m)
+        for m in self.m:
+            y.append(m(y[-1]))
         return self.cv2(torch.cat(y, 1))
 
     def forward_split(self, x):
         """Forward pass using split() instead of chunk()."""
         y = list(self.cv1(x).split((self.c, self.c), 1))
-        y.extend(m(y[-1]) for m in self.m)
+        for m in self.m:
+            y.append(m(y[-1]))
         return self.cv2(torch.cat(y, 1))
 
 
@@ -462,14 +465,16 @@ class C2fAttn(nn.Module):
     def forward(self, x, guide):
         """Forward pass through C2f layer."""
         y = list(self.cv1(x).chunk(2, 1))
-        y.extend(m(y[-1]) for m in self.m)
+        for m in self.m:
+            y.append(m(y[-1]))
         y.append(self.attn(y[-1], guide))
         return self.cv2(torch.cat(y, 1))
 
     def forward_split(self, x, guide):
         """Forward pass using split() instead of chunk()."""
         y = list(self.cv1(x).split((self.c, self.c), 1))
-        y.extend(m(y[-1]) for m in self.m)
+        for m in self.m:
+            y.append(m(y[-1]))
         y.append(self.attn(y[-1], guide))
         return self.cv2(torch.cat(y, 1))
 
