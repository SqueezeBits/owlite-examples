diff --git a/main.py b/main.py
index 129edae..be4b3df 100644
--- a/main.py
+++ b/main.py
@@ -5,6 +5,7 @@ import os
 import random
 import argparse
 import numpy as np
+import copy
 
 from torch.utils import data
 from datasets import VOCSegmentation, Cityscapes
@@ -19,6 +20,8 @@ from PIL import Image
 import matplotlib
 import matplotlib.pyplot as plt
 
+import owlite
+
 
 def get_argparser():
     parser = argparse.ArgumentParser()
@@ -46,19 +49,19 @@ def get_argparser():
     parser.add_argument("--test_only", action='store_true', default=False)
     parser.add_argument("--save_val_results", action='store_true', default=False,
                         help="save segmentation results to \"./results\"")
-    parser.add_argument("--total_itrs", type=int, default=30e3,
-                        help="epoch number (default: 30k)")
-    parser.add_argument("--lr", type=float, default=0.01,
-                        help="learning rate (default: 0.01)")
+    parser.add_argument("--total_itrs", type=int, default=3e2,
+                        help="epoch number (default: 300)")
+    parser.add_argument("--lr", type=float, default=1e-5,
+                        help="learning rate (default: 0.00001)")
     parser.add_argument("--lr_policy", type=str, default='poly', choices=['poly', 'step'],
                         help="learning rate scheduler policy")
     parser.add_argument("--step_size", type=int, default=10000)
-    parser.add_argument("--crop_val", action='store_true', default=False,
+    parser.add_argument("--crop_val", action='store_true', default=True,
                         help='crop validation (default: False)')
     parser.add_argument("--batch_size", type=int, default=16,
                         help='batch size (default: 16)')
-    parser.add_argument("--val_batch_size", type=int, default=4,
-                        help='batch size for validation (default: 4)')
+    parser.add_argument("--val_batch_size", type=int, default=16,
+                        help='batch size for validation (default: 16)')
     parser.add_argument("--crop_size", type=int, default=513)
 
     parser.add_argument("--ckpt", default=None, type=str,
@@ -81,7 +84,7 @@ def get_argparser():
                         help="download datasets")
 
     # PASCAL VOC Options
-    parser.add_argument("--year", type=str, default='2012',
+    parser.add_argument("--year", type=str, default='2012_aug',
                         choices=['2012_aug', '2012', '2011', '2009', '2008', '2007'], help='year of VOC')
 
     # Visdom options
@@ -93,6 +96,18 @@ def get_argparser():
                         help='env for visdom')
     parser.add_argument("--vis_num_samples", type=int, default=8,
                         help='number of samples for visualization (default: 8)')
+
+    # Owlite
+    subparsers = parser.add_subparsers(required=True)
+    owlite_parser = subparsers.add_parser("owlite", help="Owlite arguments")
+    owlite_parser.add_argument('--project', type=str, required=True, dest="owlite_project", help="Owlite project name")
+    owlite_parser.add_argument('--baseline', type=str, required=True, dest="owlite_baseline", help="Owlite baseline name")
+    owlite_parser.add_argument('--experiment', type=str, default=None, dest="owlite_experiment", help="Owlite experiment name")
+    owlite_parser.add_argument('--duplicate-from', type=str, default=None, dest="owlite_duplicate_from", help="The name of Owlite experiment where the config to be duplicated is located")
+    owlite_parser.add_argument('--ptq', action="store_true", dest="owlite_ptq", help="True if Owlite PTQ is applied")
+    owlite_parser.add_argument('--qat', action="store_true", dest="owlite_qat", help="True if Owlite QAT is applied")
+    owlite_parser.add_argument('--calib-num', type=int, default=256, dest="owlite_calib_num", help="Number of data to use for Owlite calibration")
+
     return parser
 
 
@@ -239,7 +254,8 @@ def main():
         train_dst, batch_size=opts.batch_size, shuffle=True, num_workers=2,
         drop_last=True)  # drop_last=True to ignore single-image batches.
     val_loader = data.DataLoader(
-        val_dst, batch_size=opts.val_batch_size, shuffle=True, num_workers=2)
+        val_dst, batch_size=opts.val_batch_size, shuffle=True, num_workers=2,
+        drop_last=True)
     print("Dataset: %s, Train set: %d, Val set: %d" %
           (opts.dataset, len(train_dst), len(val_dst)))
 
@@ -253,16 +269,18 @@ def main():
     metrics = StreamSegMetrics(opts.num_classes)
 
     # Set up optimizer
-    optimizer = torch.optim.SGD(params=[
-        {'params': model.backbone.parameters(), 'lr': 0.1 * opts.lr},
-        {'params': model.classifier.parameters(), 'lr': opts.lr},
-    ], lr=opts.lr, momentum=0.9, weight_decay=opts.weight_decay)
-    # optimizer = torch.optim.SGD(params=model.parameters(), lr=opts.lr, momentum=0.9, weight_decay=opts.weight_decay)
-    # torch.optim.lr_scheduler.StepLR(optimizer, step_size=opts.lr_decay_step, gamma=opts.lr_decay_factor)
-    if opts.lr_policy == 'poly':
-        scheduler = utils.PolyLR(optimizer, opts.total_itrs, power=0.9)
-    elif opts.lr_policy == 'step':
-        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=opts.step_size, gamma=0.1)
+    def set_optimizer(model):
+        optimizer = torch.optim.SGD(params=[
+            {'params': model.parameters(), 'lr': opts.lr},
+        ], lr=opts.lr, momentum=0.9, weight_decay=opts.weight_decay)
+        # optimizer = torch.optim.SGD(params=model.parameters(), lr=opts.lr, momentum=0.9, weight_decay=opts.weight_decay)
+        # torch.optim.lr_scheduler.StepLR(optimizer, step_size=opts.lr_decay_step, gamma=opts.lr_decay_factor)
+        if opts.lr_policy == 'poly':
+            scheduler = utils.PolyLR(optimizer, opts.total_itrs, power=0.9)
+        elif opts.lr_policy == 'step':
+            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=opts.step_size, gamma=0.1)
+        return optimizer, scheduler
+    optimizer, scheduler = set_optimizer(model)
 
     # Set up criterion
     # criterion = utils.get_loss(opts.loss_type)
@@ -292,7 +310,6 @@ def main():
         # https://github.com/VainF/DeepLabV3Plus-Pytorch/issues/8#issuecomment-605601402, @PytaichukBohdan
         checkpoint = torch.load(opts.ckpt, map_location=torch.device('cpu'))
         model.load_state_dict(checkpoint["model_state"])
-        model = nn.DataParallel(model)
         model.to(device)
         if opts.continue_training:
             optimizer.load_state_dict(checkpoint["optimizer_state"])
@@ -304,13 +321,47 @@ def main():
         del checkpoint  # free memory
     else:
         print("[!] Retrain")
-        model = nn.DataParallel(model)
         model.to(device)
 
-    # ==========   Train Loop   ==========#
-    vis_sample_id = np.random.randint(0, len(val_loader), opts.vis_num_samples,
-                                      np.int32) if opts.enable_vis else None  # sample idxs for visualization
+    owl = owlite.init(
+        project=opts.owlite_project,
+        baseline=opts.owlite_baseline,
+        experiment=opts.owlite_experiment,
+    )
+
+    model.eval()
+    batch_size = opts.batch_size
+    random_input = torch.randn(batch_size, 3, opts.crop_size, opts.crop_size, dtype=torch.float)
+    model = owl.convert(model, random_input)
+
+    if opts.owlite_ptq or opts.owlite_qat:
+        with owlite.calibrate(model) as calibrate_model:
+            for i, (train_data, _) in enumerate(train_loader):
+                calibrate_model(train_data.to(device))
+                if i + 1 >= opts.owlite_calib_num // batch_size:
+                    break
+
+    vis_sample_id = (
+        np.random.randint(0, len(val_loader), opts.vis_num_samples, np.int32) if opts.enable_vis else None
+    )  # sample idxs for visualization
     denorm = utils.Denormalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # denormalization for ori images
+    if not opts.owlite_qat:
+        owl.benchmark(model)
+        val_score, ret_samples = validate(
+            opts=opts,
+            model=model,
+            loader=val_loader,
+            device=device,
+            metrics=metrics,
+            ret_samples_ids=vis_sample_id,
+        )
+        print(metrics.to_str(val_score))
+        val_score.pop("Class IoU") # Owlite log() doesn't accept nested dict as its input
+        owl.log(**val_score)
+        return
+
+    # ==========   Train Loop   ==========#
+    optimizer, scheduler = set_optimizer(model)
 
     if opts.test_only:
         model.eval()
@@ -320,7 +371,8 @@ def main():
         return
 
     interval_loss = 0
-    while True:  # cur_itrs < opts.total_itrs:
+    best_state_dict = copy.deepcopy(model.state_dict())
+    while cur_itrs < opts.total_itrs:
         # =====  Train  =====
         model.train()
         cur_epochs += 1
@@ -358,8 +410,9 @@ def main():
                 print(metrics.to_str(val_score))
                 if val_score['Mean IoU'] > best_score:  # save best model
                     best_score = val_score['Mean IoU']
-                    save_ckpt('checkpoints/best_%s_%s_os%d.pth' %
+                    save_ckpt('checkpoints/new_best_%s_%s_os%d.pth' %
                               (opts.model, opts.dataset, opts.output_stride))
+                    best_state_dict = copy.deepcopy(model.state_dict())
 
                 if vis is not None:  # visualize validation score and samples
                     vis.vis_scalar("[Val] Overall Acc", cur_itrs, val_score['Overall Acc'])
@@ -373,10 +426,24 @@ def main():
                         concat_img = np.concatenate((img, target, lbl), axis=2)  # concat along width
                         vis.vis_image('Sample %d' % k, concat_img)
                 model.train()
-            scheduler.step()
-
             if cur_itrs >= opts.total_itrs:
-                return
+                break
+            scheduler.step()
+    
+    model.load_state_dict(best_state_dict)
+    model.eval()
+    owl.benchmark(model)
+    val_score, ret_samples = validate(
+        opts=opts,
+        model=model,
+        loader=val_loader,
+        device=device,
+        metrics=metrics,
+        ret_samples_ids=vis_sample_id,
+    )
+    print(metrics.to_str(val_score))
+    val_score.pop("Class IoU") # Owlite log() doesn't accept nested dict as its input
+    owl.log(**val_score)
 
 
 if __name__ == '__main__':
diff --git a/requirements.txt b/requirements.txt
index 48b62a8..6f98751 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,4 +1,4 @@
-torch
+torch>=2.1
 torchvision
 numpy
 pillow
